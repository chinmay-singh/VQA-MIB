| Paper         | Interest      | Again?  |
| ------------- |:-------------:| -----:|
|[Attending to Future Tokens for Bidirectional Sequence Generation](https://www.aclweb.org/anthology/D19-1001.pdf)    | They replaced the future tokens with the masks like BERT and then ran the system| No |
| [Attention is not not explaination](https://www.aclweb.org/anthology/D19-1002.pdf) | BS    |   No |
| [Transfer Learning Between Related Tasks Using Expected Label Proportionsn](https://www.aclweb.org/anthology/D19-1004.pdf) | Expectation Regularization, XR framework, Leverage Doc Sentiment for ABSA     |   Yes |
| [Knowledge Enhanced Contextual Word Representations](https://www.aclweb.org/anthology/D19-1002.pdf) | Include large Knowledge Bases to large Models  |   Yes |
| [Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings](https://www.aclweb.org/anthology/D19-1005.pdf) | Stanford    |   No |
| [Correlations between Word Vector Sets](https://www.aclweb.org/anthology/D19-1006.pdf) | Why the Language Models are making context specific representations    |   NR |
| [Game Theory Meets Embeddings:a Unified Framework for WSD](https://www.aclweb.org/anthology/D19-1009.pdf) | WOrds are players and their sense is the strategy that it can use    |   Maybe |
| [Reward Estimation for Multi-Domain Task-Oriented Dialog](https://www.aclweb.org/anthology/D19-1010.pdf) | RL in dialog for objective function and topic of conversation   |   No |
| [Multi-hop Selector Network for Multi-turn Response Selection in Retrieval-based Chatbots](https://www.aclweb.org/anthology/D19-1011.pdf) | Choose what part of context in relevant  |   No |
| [Entity-Consistent End-to-end Task-Oriented Dialogue System with KBRetriever](https://www.aclweb.org/anthology/D19-1013.pdf) |  distant supervision and Gumbel-Softmax technique.   |   No |
| [Building Task-Oriented Visual Dialog Systems Through Alternative Optimization Between Dialog Policy and Language Generationn](https://www.aclweb.org/anthology/D19-1014.pdf) | YES    |   No |
| [Attention is not not explaination](https://www.aclweb.org/anthology/D19-1002.pdf) | BS    |   No |
| [Attention is not not explaination](https://www.aclweb.org/anthology/D19-1002.pdf) | BS    |   No |
| [Attention is not not explaination](https://www.aclweb.org/anthology/D19-1002.pdf) | BS    |   No |
| [Attention is not not explaination](https://www.aclweb.org/anthology/D19-1002.pdf) | BS    |   No |
| [Attention is not not explaination](https://www.aclweb.org/anthology/D19-1002.pdf) | BS    |   No |
| [Attention is not not explaination](https://www.aclweb.org/anthology/D19-1002.pdf) | BS    |   No |
